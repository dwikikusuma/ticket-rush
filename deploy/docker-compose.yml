version: "3.8"

services:
  # --- 1. DATABASES ---

  postgres:
    image: postgres:15-alpine
    container_name: ticket_postgres
    hostname: postgres
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: ticket_db
    ports:
      - "5432:5432"
    volumes:
      - ticket_postgres_data:/var/lib/postgresql/data
    networks:
      - ticket_net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d ticket_db"]
      interval: 5s
      timeout: 5s
      retries: 5

  mongo:
    image: mongo:6.0
    container_name: ticket_mongo
    hostname: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: user
      MONGO_INITDB_ROOT_PASSWORD: password
    ports:
      - "27017:27017"
    volumes:
      - ticket_mongo_data:/data/db
    networks:
      - ticket_net
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7.2-alpine
    container_name: ticket_redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - ticket_redis_data:/data
    networks:
      - ticket_net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.9
    container_name: ticket_elastic
    hostname: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - ticket_elastic_data:/usr/share/elasticsearch/data
    networks:
      - ticket_net
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 >/dev/null || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # --- 2. MESSAGE BROKER (KRaft Mode - No Zookeeper!) ---

  kafka:
    image: bitnamilegacy/kafka:latest
    container_name: ticket_kafka
    hostname: kafka
    ports:
      - "9092:9092" # External access
    environment:
      # KRaft Settings
      KAFKA_CFG_NODE_ID: 1
      KAFKA_CFG_PROCESS_ROLES: controller,broker
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      
      # Listeners
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,INTERNAL://:9094
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:9094
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: INTERNAL
      
      # Persistence & Replication
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR: 1
    volumes:
      - ticket_kafka_data:/bitnami/kafka
    networks:
      - ticket_net
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: ticket_kafka_ui
    ports:
      - "8088:8080" # Access at http://localhost:8088
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: ticket_rush_cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9094
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - ticket_net

  # This container runs ONCE to create our topics automatically
  init-kafka:
    image: bitnamilegacy/kafka:latest
    container_name: ticket_init_kafka
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - ticket_net
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "
      echo 'Waiting for Kafka...'
      until kafka-topics.sh --bootstrap-server kafka:9094 --list >/dev/null 2>&1; do
        echo 'Broker not available yet... waiting 2s'
        sleep 2
      done

      echo 'Kafka is UP. Creating TicketRush topics...'

      # Core Business Events
      kafka-topics.sh --create --if-not-exists --topic booking.created    --bootstrap-server kafka:9094 --partitions 3 --replication-factor 1
      kafka-topics.sh --create --if-not-exists --topic ticket.issued      --bootstrap-server kafka:9094 --partitions 3 --replication-factor 1
      kafka-topics.sh --create --if-not-exists --topic booking.failed     --bootstrap-server kafka:9094 --partitions 3 --replication-factor 1
      
      # Analytics & Dead Letter Queues
      kafka-topics.sh --create --if-not-exists --topic analytics.view     --bootstrap-server kafka:9094 --partitions 1 --replication-factor 1
      kafka-topics.sh --create --if-not-exists --topic dlq.booking        --bootstrap-server kafka:9094 --partitions 1 --replication-factor 1

      echo 'SUCCESS: Topics created.'
      kafka-topics.sh --bootstrap-server kafka:9094 --list
      "

  # --- 3. OBSERVABILITY ---

  prometheus:
    image: prom/prometheus:latest
    container_name: ticket_prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ticket_prometheus_data:/prometheus
    networks:
      - ticket_net
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9090/-/ready >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  grafana:
    image: grafana/grafana:latest
    container_name: ticket_grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: password
    volumes:
      - ticket_grafana_data:/var/lib/grafana
    networks:
      - ticket_net
    depends_on:
      prometheus:
        condition: service_healthy

networks:
  ticket_net:
    driver: bridge

volumes:
  ticket_postgres_data:
  ticket_mongo_data:
  ticket_redis_data:
  ticket_elastic_data:
  ticket_kafka_data:
  ticket_prometheus_data:
  ticket_grafana_data:
